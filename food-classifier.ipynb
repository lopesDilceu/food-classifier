{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "773fab9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import numpy as np\n",
    "\n",
    "# Aumenta a qualidade das imagens plotadas no notebook\n",
    "plt.rcParams[\"figure.dpi\"] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696730a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho para os dataset\n",
    "data_dir = pathlib.Path('dataset/')\n",
    "\n",
    "# Define os caminhos para treino e validação\n",
    "train_dir = data_dir / 'training'\n",
    "validation_dir = data_dir / 'validation'\n",
    "evaluation_dir = data_dir / 'evaluation'\n",
    "\n",
    "# Parâmetros do modelo\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 32 # Quantas imagens o modelo vê por vez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07d2279d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9866 files belonging to 11 classes.\n",
      "Found 3430 files belonging to 11 classes.\n",
      "Classes encontradas: ['Bread', 'Dairy product', 'Dessert', 'Egg', 'Fried food', 'Meat', 'Noodles-Pasta', 'Rice', 'Seafood', 'Soup', 'Vegetable-Fruit']\n"
     ]
    }
   ],
   "source": [
    "# Carrega o dataset de treino\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  train_dir,\n",
    "  labels='inferred',\n",
    "  label_mode='int', # Rótulos como inteiros (0 para Bread, 1 para Dairy, etc.)\n",
    "  image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "  batch_size=BATCH_SIZE)\n",
    "\n",
    "# Carrega o dataset de validação\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  validation_dir,\n",
    "  labels='inferred',\n",
    "  label_mode='int',\n",
    "  image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "  batch_size=BATCH_SIZE)\n",
    "\n",
    "# Guarda os nomes das classes para usar depois\n",
    "class_names = train_ds.class_names\n",
    "print(\"Classes encontradas:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c73ae635",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c5efcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetv2-b0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,919,312</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,091</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential (\u001b[38;5;33mSequential\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetv2-b0 (\u001b[38;5;33mFunctional\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m5,919,312\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)             │        \u001b[38;5;34m14,091\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,933,403</span> (22.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,933,403\u001b[0m (22.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,091</span> (55.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,091\u001b[0m (55.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,919,312</span> (22.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m5,919,312\u001b[0m (22.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Camada de Data Augmentation\n",
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "  ]\n",
    ")\n",
    "\n",
    "# Modelo Base\n",
    "# A camada de reescala já está incluída no EfficientNet\n",
    "base_model = tf.keras.applications.EfficientNetV2B0(\n",
    "    input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n",
    "    include_top=False, # Não incluir a camada classificadora final\n",
    "    weights='imagenet' # Carregar pesos pré-treinados na ImageNet\n",
    ")\n",
    "\n",
    "# Congelar o modelo base para não retreiná-lo inicialmente\n",
    "base_model.trainable = False\n",
    "\n",
    "# Montagem do Modelo Completo\n",
    "inputs = keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = base_model(x, training=False) # 'training=False' é importante aqui\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.2)(x) # Dropout para regularização\n",
    "outputs = layers.Dense(len(class_names))(x) # Camada final com 11 neurônios\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ad79ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18eaff45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 331ms/step - accuracy: 0.5869 - loss: 1.3166 - val_accuracy: 0.8292 - val_loss: 0.5537\n",
      "Epoch 2/20\n",
      "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 282ms/step - accuracy: 0.8125 - loss: 0.5774 - val_accuracy: 0.8551 - val_loss: 0.4612\n",
      "Epoch 3/20\n",
      "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 279ms/step - accuracy: 0.8420 - loss: 0.4903 - val_accuracy: 0.8685 - val_loss: 0.4256\n",
      "Epoch 4/20\n",
      "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 282ms/step - accuracy: 0.8514 - loss: 0.4599 - val_accuracy: 0.8723 - val_loss: 0.4057\n",
      "Epoch 5/20\n",
      "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 286ms/step - accuracy: 0.8594 - loss: 0.4319 - val_accuracy: 0.8787 - val_loss: 0.3870\n",
      "Epoch 6/20\n",
      "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 285ms/step - accuracy: 0.8642 - loss: 0.4179 - val_accuracy: 0.8805 - val_loss: 0.3778\n",
      "Epoch 7/20\n",
      "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 281ms/step - accuracy: 0.8678 - loss: 0.3970 - val_accuracy: 0.8854 - val_loss: 0.3680\n",
      "Epoch 8/20\n",
      "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 285ms/step - accuracy: 0.8774 - loss: 0.3758 - val_accuracy: 0.8854 - val_loss: 0.3646\n",
      "Epoch 9/20\n",
      "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 282ms/step - accuracy: 0.8795 - loss: 0.3710 - val_accuracy: 0.8898 - val_loss: 0.3566\n",
      "Epoch 10/20\n",
      "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 282ms/step - accuracy: 0.8787 - loss: 0.3680 - val_accuracy: 0.8878 - val_loss: 0.3483\n",
      "Epoch 11/20\n",
      "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 290ms/step - accuracy: 0.8841 - loss: 0.3445 - val_accuracy: 0.8883 - val_loss: 0.3493\n",
      "Epoch 12/20\n",
      "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 283ms/step - accuracy: 0.8808 - loss: 0.3569 - val_accuracy: 0.8904 - val_loss: 0.3431\n",
      "Epoch 13/20\n",
      "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 283ms/step - accuracy: 0.8827 - loss: 0.3520 - val_accuracy: 0.8889 - val_loss: 0.3407\n",
      "Epoch 14/20\n",
      "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 287ms/step - accuracy: 0.8874 - loss: 0.3502 - val_accuracy: 0.8898 - val_loss: 0.3401\n",
      "Epoch 15/20\n",
      "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 286ms/step - accuracy: 0.8817 - loss: 0.3376 - val_accuracy: 0.8913 - val_loss: 0.3396\n",
      "Epoch 16/20\n",
      "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 283ms/step - accuracy: 0.8868 - loss: 0.3334 - val_accuracy: 0.8930 - val_loss: 0.3364\n",
      "Epoch 17/20\n",
      "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 284ms/step - accuracy: 0.8910 - loss: 0.3257 - val_accuracy: 0.8924 - val_loss: 0.3337\n",
      "Epoch 18/20\n",
      "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 282ms/step - accuracy: 0.8913 - loss: 0.3209 - val_accuracy: 0.8904 - val_loss: 0.3324\n",
      "Epoch 19/20\n",
      "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 285ms/step - accuracy: 0.8900 - loss: 0.3265 - val_accuracy: 0.8921 - val_loss: 0.3357\n",
      "Epoch 20/20\n",
      "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 282ms/step - accuracy: 0.8946 - loss: 0.3026 - val_accuracy: 0.8907 - val_loss: 0.3327\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04ee4dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo salvo com sucesso em: food11_efficientnet_model.keras\n"
     ]
    }
   ],
   "source": [
    "# Define o caminho e o nome do arquivo para salvar o modelo\n",
    "model_save_path = 'food11_efficientnet_model.keras'\n",
    "\n",
    "# Salva o modelo inteiro (arquitetura, pesos e configuração do otimizador)\n",
    "model.save(model_save_path)\n",
    "\n",
    "print(f\"Modelo salvo com sucesso em: {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67135e0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluation_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     18\u001b[39m     plt.show()\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Teste com uma imagem da pasta de avaliação\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Mude o nome do arquivo para testar outras imagens\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m predict_image(\u001b[43mevaluation_dir\u001b[49m / \u001b[33m'\u001b[39m\u001b[33mMeat/123.jpg\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'evaluation_dir' is not defined"
     ]
    }
   ],
   "source": [
    "# Função para carregar uma imagem e fazer a previsão\n",
    "def predict_image(image_path):\n",
    "    img = keras.utils.load_img(\n",
    "        image_path, target_size=(IMG_HEIGHT, IMG_WIDTH)\n",
    "    )\n",
    "    img_array = keras.utils.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0) # Cria um batch\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "    score = tf.nn.softmax(predictions[0]) # Aplica softmax para obter probabilidades\n",
    "\n",
    "    predicted_class = class_names[np.argmax(score)]\n",
    "    confidence = 100 * np.max(score)\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Predição: {predicted_class}\\nConfiança: {confidence:.2f}%\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Teste com uma imagem da pasta de avaliação\n",
    "# Mude o nome do arquivo para testar outras imagens\n",
    "predict_image(evaluation_dir / 'Meat/123.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
